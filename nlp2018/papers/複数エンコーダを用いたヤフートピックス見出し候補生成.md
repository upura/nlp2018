# 複数エンコーダを用いたヤフートピックス見出し候補生成
- 小林健 (ヤフー), 小林隼人 (ヤフー/理研AIP), 村尾一真, 増山毅司 (ヤフー)
- 言語処理学会第24回年次大会(NLP2018)
- http://anlp.jp/proceedings/annual_meeting/2018/pdf_dir/A1-3.pdf

# どんなもの？
- Yahoo! ニュース・トピックスの見出し（13.5文字以内）の候補を自動生成
- エンコーダ・デコーダの枠組みを利用
  - トピックスページ中の記事タイトルと記事リード文を同時に利用するため，エンコーダ・デコーダの枠組みを拡張し，複数のエンコーダ出力を用いてトピックス見出しを生成する手法を提案

# 先行研究と比べてどこがすごい？
-  Multimodal Attention モデル
  - Hori らによる動画の説明文生成に関する研究 [5]
  - 映像用のエンコーダ，音声用のエンコーダ等を利用して動画の説明文をエンコーダ・デコーダの枠組みで生成
  - エンコーダごとにスカラーの重みを動的に計算し，その重み付き和ベクトルを利用することで，精度が向上
  - 重みをスカラー値で計算し，これを掛けることによって重み付き和を計算
- 本研究
  - 要素ごとに重みを計算できれば，より適切な特徴を表現できると予想し，複数エンコーダの出力を統合する手法を提案

# 技術や手法のキモはどこ？
- 複数エンコーダを利用する「Multimodal Attention モデル」の改良
- 入力
  - 記事リード文
  - 記事タイトル
- 出力
- トピックス見出し

# どうやって有効だと検証した？
- Yahoo!ニュース・トピックスで掲載されたニュース記事を利用
- 要約タスクの評価指標として利用されている ROUGE値と、人手で評価（1記事当たり10人、平均を採用）

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/u/upura/20180506/20180506132051.png">

# 議論はある？
実験結果の細部について議論

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/u/upura/20180506/20180506132206.png">

# 次に読むべき論文は？
- Multimodal Attention モデル
  - [5] Chiori Hori, Takaaki Hori, Teng-Yok Lee, Ziming Zhang, Bret Harsham, John R. Hershey, Tim K. Marks, and Kazuhiko Sumi. Attention-Based Multimodal Fusion for Video Description. In ICCV, 2017.
- Query-based Attention モデル
  - [4] Preksha Nema, Mitesh M. Khapra, Anirban Laha, and Balaraman Ravindran. Diversity driven attention model for query-based abstractive summarization. In ACL, pp. 1063–1072, 2017.
